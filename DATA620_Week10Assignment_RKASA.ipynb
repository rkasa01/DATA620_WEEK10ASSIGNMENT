{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Week Ten - Assignment: Document Classification\n",
        "\n",
        "## Prompt:\n",
        "\n",
        "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set\n",
        "\n",
        "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
        "\n",
        "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified."
      ],
      "metadata": {
        "id": "8roAqWc4v5bT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "A5ufCGCFypOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qjoa1gBLvyRe"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import random\n",
        "import pandas as pd\n",
        "random.seed(1)\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "LqG7BpNZ0h3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200: #check request\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    links = soup.find_all('a')\n",
        "    filenames = [\"20021010_easy_ham.tar.bz2\", \"20030228_spam.tar.bz2\"]\n",
        "\n",
        "    save_dir = \"./downloaded_emails\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for link in links:\n",
        "        href = link.get('href')\n",
        "        if href in filenames:\n",
        "            download_url = url + href\n",
        "\n",
        "            os.system(f\"wget -P {save_dir} {download_url}\") # wget downloads files\n",
        "\n",
        "            print(f\"Downloaded {href} successfully.\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the webpage.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvgUpj4l0hZ9",
        "outputId": "b7522c81-6741-45b6-fee9-3f348d9d3c13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 20021010_easy_ham.tar.bz2 successfully.\n",
            "Downloaded 20030228_spam.tar.bz2 successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I first started by extracting data from the spamassassin public corpus which can be found here: https://spamassassin.apache.org/old/publiccorpus/. I downloaded one ham (\"20021010_easy_ham.tar.bz2\") and one spam (\"20030228_spam.tar.bz2\") folder."
      ],
      "metadata": {
        "id": "iV9eJQHY0jdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Is2g5Rpn8sLU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVkBl0NC8rkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZQBLznPl8rMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presentation Link"
      ],
      "metadata": {
        "id": "Z3jkym_l8oD7"
      }
    }
  ]
}